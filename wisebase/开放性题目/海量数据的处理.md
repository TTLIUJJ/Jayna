# 海量数据的处理

1GB = 1024MB = (1024kb x 1024kb)byte = (1024 x 1024 x 1024)byte ~ (10亿)byte

2 ^32 = 40亿多

- 用到的思路：
	- Hash
	- 分治
	- 堆
	- 排序

## 分而治之

#### 1. 给40亿个不重复的未排序的unsigned int的整数，现在给定一个数x，如何快速判断x是否在40亿个数中？

一个unsigned int占据的内存空间为32位，4个字节，现在有40亿个数字，即一次性排序需要的4x4GB内存，16GB的内存普通电脑明显是排序不了的。
	 
- 将40亿个分成两堆：
	- 最高位为1
	- 最高位为0
	- 舍弃最高位与x不同的那些数
- 将20亿个数分成两堆：
	- 次高位为1
	- 次高位为0
	- 舍弃次高位与x不同的那些数
- ...重复上述操作直至最低位
- 时间复杂度O(logN), N为40亿

#### 2. 海量日志数据，提取出某日访问百度次数最多的那个IP

- 32位的IP地址最多有2^32=4G种的取值情况，
- 把海量IP日志分别存储在1024个文件，每个小文件包含4M个IP地址
- 对于每个小文件，可以使用TreeHashMap进行维护，以IP为Key，以出现的次数为Value，堆顶IP即小文件访问次数最多的IP
- 对1024个IP再次使用TreeHashMap进行维护

#### 3. 给定a,b两个文件，各存放50亿个url，每个url各占64字节，找出a,b中相同的url，内存限制是4GB

- 5 x 64 = 320GB，远大于内存的4G限制
- 对于a文件，对每个url求hash(url)%1024，并且分成1024个文件，每个文件大小为320MB，记[a0, a1, a2, ... , a1023] ，每个ai中有320MB的url
- 对于b文件，执行上述相同的操作
- 因为相同的url肯定有相同的hash(url)%1024值，那么ai和bi中可能就会存在相同的url，求交集即可

#### 4. 有一个1个G大小的文件，里面的每一行都是一个词，词的大小不超过16字节，内存限制大小是1M，返回频率出现最高的100个词

- 拆分文件，1GB/0.5MB = 2000个文件，每个文件0.5MB的词+统计的频率，小于1M
- 对每个文件得到的词频进行排序，取前100个，生成对应的新文件
- 对2000个新生成的文件进行外排序

## TOP K

#### 5. 搜索引擎会通过日志文件把用户每次检索使用的所有字符串记录下来，每个查询字符串自多为255字节

补充题目：假设目前有1千万个查询，里面有重复的查询，事实上只有300万个不同的查询，重复度越高说明热度越高，现在要统计10个最热门查询串，要求使用的内存不能超过1G。

- 最多有0.1亿x255字节=25.5亿字节～2.5GB内存，内存明显不够用
- 考虑到只有300万个不同的Query，2.5/3 < 1 GB，内存可以存放300万个不同的字符串，以Query为Key，Query出现的次数为Value，建立hash表
- 使用最小堆进行排序，比较Query为堆元素，比较Query的次数


#### 6. 有10个文件，每个文件１个G，每一行存放的都是用户的Query，每个文件Query都可能重复，求Query的频度查询

- 顺序读取10个文件，按照Hash(Query)的结果将Query写入到另外的10个文件中，新文件也就1个G左右（增加Query_Count字段和减少的重复Query）
- 找一台2G以上内存的电脑，使用HashMap<Query, QueryCount>对每个预处理过的文件进行词频统计，再进行排序
- 对这10个文件进行归并处理（外排序）

## 位图计算法

#### 7. 在2.5亿个整数中找出不重复的整数，注：内存不足以容纳所有的整数


位图计算法：整个一共有2^32～4G个，那么需要4x4＝16GB的内存，现在使用0.1字节即1bit来表示一个整数，那么总共需要4x0.125=0.5GB的内存，就可以存放所有的整数。

- 使用两个位图数组，即需要1GB的内存，位图数组1记录第一次出现的整数，位图数组2记录第二次出现的整数，
- 遍历这两个数组，可以分成三种情况，未出现的整数，出现一次的整数，出现两次及其以上的整数。